### Задача: Рефакторинг Тестов с Использованием Централизованной Mock Factory

**ID Задачи:** T-003
**Приоритет:** Высокий (Технический долг)
**Оценка:** 2-3 дня (инкрементально)
**Статус:** К выполнению

**1. Проблема:**
Текущая тестовая база (>25 тестов, >260 использований моков) страдает от хаотичного и неконсистентного создания моков. Логика мокирования API-ответов Binance, логгеров и других зависимостей дублируется в десятках файлов. Это приводит к:
- **Замедлению разработки:** Написание новых тестов требует копирования и адаптации громоздких конструкций.
- **Хрупкости тестов:** Изменение в API требует правок во многих местах, что увеличивает риск ошибок.
- **Плохой читаемости:** Тесты загромождены кодом для настройки моков, что скрывает их основную цель.

**2. Решение:**
Создать централизованную **Mock Factory** (`tests/fixtures/mock_factory.py`), которая станет единым источником для генерации всех тестовых моков и данных. Это позволит инкапсулировать логику создания моков и предоставлять консистентные, готовые к использованию мок-объекты для тестов.

**3. План Реализации:**

**Этап 1: Создание Фабрики (2-3 часа)**
- [ ] Создать файл `tests/fixtures/mock_factory.py`.
- [ ] Реализовать класс `MockFactory`.
- [ ] Добавить статические методы для генерации наиболее частых моков:
    - `create_successful_klines_response(data, symbol)`
    - `create_rate_limit_response()`
    - `create_api_error_response(status_code)`
    - `create_insufficient_data_response()`
    - `generate_realistic_klines(count, base_price)`

**Этап 2: Инкрементальный Рефакторинг Тестов (2-3 дня)**
- [ ] **Цель:** Заменить все инлайновые создания `Mock` и `MagicMock` на вызовы `MockFactory`.
- [ ] **Приоритетные файлы для рефакторинга:**
    - `tests/integration/error_architecture/test_error_integration.py`
    - `tests/unit/test_market_data_service.py`
    - `tests/integration/market_data/test_market_data_integration.py`
    - `tests/unit/market_data/test_market_data_api.py`
- [ ] Провести рефакторинг остальных тестов по мере возможности.

**4. Критерии Успеха:**
- Создан и используется `MockFactory`.
- >90% созданий моков в тестах заменены на вызовы фабрики.
- Тестовые файлы стали короче и чище.
- Запуск всех тестов (`pytest`) проходит успешно после рефакторинга.

---

### Задача: Устранение избыточных API-запросов в MarketDataService

**ID Задачи:** T-004
**Приоритет:** Средний
**Оценка:** 1 день
**Статус:** Бэклог

**1. Проблема:**
Метод `get_enhanced_context()` вызывает `get_market_data()`, что приводит к многократной повторной загрузке одних и тех же данных с Binance API. Это является причиной низкой производительности и лишних расходов на API.

**2. Решение:**
Провести рефакторинг `get_enhanced_context()` таким образом, чтобы он принимал в качестве аргумента уже существующий объект `MarketDataSet`. Внутри метода использовать переданные данные, а не запрашивать их заново.

**3. План Реализации:**
- [ ] Изменить сигнатуру `get_enhanced_context(self, market_data: MarketDataSet)`.
- [ ] Удалить внутренний вызов `self.get_market_data()`.
- [ ] Адаптировать все вызовы `get_enhanced_context()` в кодовой базе для соответствия новой сигнатуре.
- [ ] Обновить юнит-тесты для проверки новой логики.

**4. Критерии Успеха:**
- Отсутствие вызовов `get_market_data()` внутри `get_enhanced_context()`.
- Все тесты, связанные с `MarketDataService`, проходят успешно.

---

### Задача: Оптимизация запросов данных для BTC в MarketDataService

**ID Задачи:** T-005
**Приоритет:** Низкий
**Оценка:** 0.5 дня
**Статус:** Бэклог

**1. Проблема:**
При анализе нескольких альткоинов в рамках одной сессии, данные для BTC (необходимые для расчета корреляции) запрашиваются каждый раз заново для каждого альткоина.

**2. Решение:**
Реализовать механизм кратковременного кеширования данных для BTC на уровне инстанса `MarketDataService`, чтобы избежать повторных запросов в рамках одной сессии анализа.

**3. План Реализации:**
- [ ] Добавить в `__init__` `MarketDataService` атрибут для кеширования, например, `self._btc_cache = {}`.
- [ ] В методе `_calculate_btc_correlation` перед запросом данных проверять наличие и актуальность кеша.
- [ ] Если данные в кеше есть и они свежие (например, не старше 5 минут), использовать их.
- [ ] Если кеш пуст или устарел, выполнить API-запрос и обновить кеш.

**4. Критерии Успеха:**
- При последовательных вызовах `get_market_data` для разных альткоинов, API-запрос для `BTCUSDT` выполняется только один раз.
- Тесты подтверждают корректную работу механизма кеширования.
